{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import math\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import from my module.\n",
    "from util import id2cat, get_cat2id, smooth_user_preference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data\n",
    "interactions_df = pd.read_csv('data/users_interactions.csv')\n",
    "\n",
    "# Process interactions_df\n",
    "event_type_strength = {\n",
    "   'VIEW': 1.0,\n",
    "   'LIKE': 2.0, \n",
    "   'BOOKMARK': 2.5, \n",
    "   'FOLLOW': 3.0,\n",
    "   'COMMENT CREATED': 4.0,  \n",
    "}\n",
    "interactions_df['eventStrength'] = interactions_df['eventType'].apply(lambda x: event_type_strength[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>eventType</th>\n",
       "      <th>contentId</th>\n",
       "      <th>personId</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>userAgent</th>\n",
       "      <th>userRegion</th>\n",
       "      <th>userCountry</th>\n",
       "      <th>eventStrength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1465413032</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>-3499919498720038879</td>\n",
       "      <td>-8845298781299428018</td>\n",
       "      <td>1264196770339959068</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1465412560</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>8890720798209849691</td>\n",
       "      <td>-1032019229384696495</td>\n",
       "      <td>3621737643587579081</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2...</td>\n",
       "      <td>NY</td>\n",
       "      <td>US</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1465416190</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>-1130272294246983140</td>\n",
       "      <td>2631864456530402479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1465413895</td>\n",
       "      <td>FOLLOW</td>\n",
       "      <td>310515487419366995</td>\n",
       "      <td>344280948527967603</td>\n",
       "      <td>-3167637573980064150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465412290</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>-7820640624231356730</td>\n",
       "      <td>-445337111692715325</td>\n",
       "      <td>5611481178424124714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    timestamp eventType            contentId             personId  \\\n",
       "0  1465413032      VIEW -3499919498720038879 -8845298781299428018   \n",
       "1  1465412560      VIEW  8890720798209849691 -1032019229384696495   \n",
       "2  1465416190      VIEW   310515487419366995 -1130272294246983140   \n",
       "3  1465413895    FOLLOW   310515487419366995   344280948527967603   \n",
       "4  1465412290      VIEW -7820640624231356730  -445337111692715325   \n",
       "\n",
       "             sessionId                                          userAgent  \\\n",
       "0  1264196770339959068                                                NaN   \n",
       "1  3621737643587579081  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2...   \n",
       "2  2631864456530402479                                                NaN   \n",
       "3 -3167637573980064150                                                NaN   \n",
       "4  5611481178424124714                                                NaN   \n",
       "\n",
       "  userRegion userCountry  eventStrength  \n",
       "0        NaN         NaN            1.0  \n",
       "1         NY          US            1.0  \n",
       "2        NaN         NaN            1.0  \n",
       "3        NaN         NaN            3.0  \n",
       "4        NaN         NaN            1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set column name mappings.\n",
    "USER_KEY = \"personId\"\n",
    "ITEM_KEY = \"contentId\"\n",
    "RATE_KEY = \"eventStrength\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# users: 1895\n",
      "# users with at least 5 interactions: 1140\n",
      "# of interactions from users with at least 5 interactions: 69868\n",
      "# of unique user/item interactions: 39106\n",
      "# interactions on Train set: 27374\n",
      "# interactions on Test set: 11732\n"
     ]
    }
   ],
   "source": [
    "tmp = interactions_df.groupby([USER_KEY, ITEM_KEY]).size()\n",
    "users_interactions_count_df = tmp.groupby(USER_KEY).size()\n",
    "\n",
    "print('# users: %d' % len(users_interactions_count_df))\n",
    "users_with_enough_interactions_df = users_interactions_count_df[users_interactions_count_df >= 5]\n",
    "users_with_enough_interactions_df = users_with_enough_interactions_df.reset_index()[[USER_KEY]]\n",
    "\n",
    "print('# users with at least 5 interactions: %d' % len(users_with_enough_interactions_df))\n",
    "interactions_from_selected_users_df = interactions_df.merge(\n",
    "    users_with_enough_interactions_df, \n",
    "    how = 'right',\n",
    "    left_on = USER_KEY,\n",
    "    right_on = USER_KEY,\n",
    ")\n",
    "print('# of interactions from users with at least 5 interactions: %d' % len(interactions_from_selected_users_df))\n",
    "interactions_full_df = interactions_from_selected_users_df \\\n",
    "                    .groupby([USER_KEY, ITEM_KEY])[RATE_KEY].sum() \\\n",
    "                    .apply(smooth_user_preference).reset_index()\n",
    "\n",
    "print('# of unique user/item interactions: %d' % len(interactions_full_df))\n",
    "# Transform all ids to categories\n",
    "u2idx, u_cat = get_cat2id(interactions_full_df[USER_KEY])\n",
    "i2idx, i_cat = get_cat2id(interactions_full_df[ITEM_KEY])\n",
    "interactions_full_df[USER_KEY] = u_cat\n",
    "interactions_full_df[ITEM_KEY] = i_cat\n",
    "\n",
    "train_size = int(0.7 * len(interactions_full_df))\n",
    "interactions_train_df = interactions_full_df[:train_size]\n",
    "interactions_test_df = interactions_full_df[train_size:]\n",
    "print('# interactions on Train set: %d' % len(interactions_train_df))\n",
    "print('# interactions on Test set: %d' % len(interactions_test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27374\n",
      "27374\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class PMF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, emb_size, lam_u, lam_v):\n",
    "        super(PMF, self).__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, emb_size)\n",
    "        self.item_emb = nn.Embedding(num_items, emb_size)\n",
    "\n",
    "        # initializing our matrices with normal distribution\n",
    "        nn.init.normal_(self.user_emb.weight)\n",
    "        self.user_emb.weight.mul(0.1)\n",
    "        nn.init.normal_(self.item_emb.weight)\n",
    "        self.item_emb.weight.mul(0.1)\n",
    "        \n",
    "        self.lam_u = lam_u\n",
    "        self.lam_v = lam_v\n",
    "\n",
    "\n",
    "    def forward(self, u, v):\n",
    "        u = self.user_emb(u)\n",
    "        v = self.item_emb(v)\n",
    "        output = (u*v).sum(1)     # taking the dot product\n",
    "        \n",
    "        # Perform Frobenius norm (but without sqrt)\n",
    "        u_reg = self.lam_u * torch.sum(u**2)\n",
    "        v_reg = self.lam_v * torch.sum(v**2)\n",
    "\n",
    "        return output, u_reg, v_reg\n",
    "\n",
    "num_users = len(interactions_train_df[USER_KEY])\n",
    "num_items = len(interactions_train_df[ITEM_KEY])\n",
    "print(num_users)\n",
    "print(num_items)\n",
    "model = PMF(num_users, num_items, emb_size=10, lam_u=0.01, lam_v=0.01)\n",
    "\n",
    "# train_df, valid_df = train_test_split(dataset, test_size=0.2)\n",
    "# resetting indices to avoid indexing errors\n",
    "train_df = interactions_train_df.reset_index(drop=True)\n",
    "test_df = interactions_test_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epocs(model, epochs=150000, lr=0.01, wd=0.0):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "#     optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.8)\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        user_tensor = torch.LongTensor(train_df[USER_KEY].values).to(device)\n",
    "        item_tensor = torch.LongTensor(train_df[ITEM_KEY].values).to(device)\n",
    "        ratings = torch.FloatTensor(train_df[RATE_KEY].values).to(device)\n",
    "        # print(torch.max(item_tensor))\n",
    "        # print(torch.min(item_tensor))\n",
    "        \n",
    "        y_hat, u_reg, v_reg = model(user_tensor, item_tensor)\n",
    "        \n",
    "        loss = F.mse_loss(y_hat, ratings) + u_reg + v_reg\n",
    "        if epoch % 10000 == 0:\n",
    "            print(f\"Epoch: {epoch}, Loss: {loss}\")\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "def test(model):\n",
    "    model.eval()\n",
    "    user_tensor = torch.LongTensor(test_df[USER_KEY].values).to(device)\n",
    "    item_tensor = torch.LongTensor(test_df[ITEM_KEY].values).to(device)\n",
    "    ratings = torch.FloatTensor(test_df[RATE_KEY].values).to(device)\n",
    "    y_hat, _, _ = model(user_tensor, item_tensor)\n",
    "    loss = F.mse_loss(y_hat, ratings)\n",
    "    print(\"test loss %.3f \" % loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 5362.302734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10003/100000 [06:11<56:00, 26.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000, Loss: 2.668125629425049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20005/100000 [12:27<48:57, 27.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20000, Loss: 2.6684916019439697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30004/100000 [18:34<42:49, 27.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30000, Loss: 2.6684257984161377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40003/100000 [24:39<36:39, 27.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40000, Loss: 2.6684744358062744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50005/100000 [30:49<30:49, 27.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50000, Loss: 2.668393135070801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60005/100000 [37:06<24:46, 26.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60000, Loss: 2.6682982444763184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 70005/100000 [43:20<18:33, 26.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70000, Loss: 2.6683874130249023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 80004/100000 [49:37<12:05, 27.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80000, Loss: 2.668389081954956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 90003/100000 [55:44<05:59, 27.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90000, Loss: 2.6683719158172607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [1:01:47<00:00, 26.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "train_epocs(model, epochs=100000)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "067e0eacdea1980316c9f0fd1ce31924ae834c9e742cdeb3825c1b6650514cfd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('Matrix_Factorization_PyTorch-7ZDEIVb8': pipenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
